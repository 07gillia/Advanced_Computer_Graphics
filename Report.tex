%\title{Project Report}
%
%%% Preamble
\documentclass[paper=a4, fontsize=11pt]{scrartcl}
\usepackage[T1]{fontenc}
\usepackage{fourier}
\usepackage{listings}
\usepackage{times}
\usepackage{harvard}

\usepackage[english]{babel}															% English language/hyphenation
\usepackage[protrusion=true,expansion=true]{microtype}	
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage[pdftex]{graphicx}	
\usepackage{url}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage[margin=1.00in]{geometry}
\usepackage{amsmath}
\usepackage[]{algorithm2e}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{braket}

\citationmode{abbr}
\bibliographystyle{agsm}

\DeclareOldFontCommand{\rm}{\normalfont\rmfamily}{\mathrm}
\DeclareOldFontCommand{\sf}{\normalfont\sffamily}{\mathsf}
\DeclareOldFontCommand{\tt}{\normalfont\ttfamily}{\mathtt}
\DeclareOldFontCommand{\bf}{\normalfont\bfseries}{\mathbf}
\DeclareOldFontCommand{\it}{\normalfont\itshape}{\mathit}
\DeclareOldFontCommand{\sl}{\normalfont\slshape}{\@nomath\sl}
\DeclareOldFontCommand{\sc}{\normalfont\scshape}{\@nomath\sc}
\DeclareRobustCommand*\cal{\@fontswitch\relax\mathcal}
\DeclareRobustCommand*\mit{\@fontswitch\relax\mathnormal}

%%% Custom sectioning
\usepackage{sectsty}
\allsectionsfont{\centering \normalfont\scshape}


%%% Custom headers/footers (fancyhdr package)
\usepackage{fancyhdr}
\pagestyle{fancyplain}
\fancyhead{}											% No page header
\fancyfoot[L]{}											% Empty 
\fancyfoot[C]{}											% Empty
\fancyfoot[R]{\thepage}									% Pagenumbering
\renewcommand{\headrulewidth}{0pt}			% Remove header underlines
\renewcommand{\footrulewidth}{0pt}				% Remove footer underlines
\setlength{\headheight}{3.6pt}
\date{}


%%% Equation and float numbering
\numberwithin{equation}{section}		% Equationnumbering: section.eq#
\numberwithin{figure}{section}			% Figurenumbering: section.fig#
\numberwithin{table}{section}				% Tablenumbering: section.tab#


%%% Maketitle metadata
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} 	% Horizontal rule

\title{
		\vspace{-1in} 	
		\usefont{OT1}{bch}{b}{n}
		\normalfont \normalsize \textsc{Durham Computer Science} \\ [5pt]
		\horrule{0.5pt} \\[0.4cm]
		\huge  Advanced Computer Graphics Summative Assignment - LLLL76\\
		\horrule{2pt} \\[0.5cm]
		\vspace{-1in} 	
}

%%% Begin document
\begin{document}
\maketitle

\section*{Question One}

\iffalse
20 marks \\
200 words \\
Compare the main difference between applying appearance-based metric and geometric based
metric to measure the quality difference between two polygon meshes. Analyse in
which part of the graphics rendering pipeline each metric should be applied to perform quality
measurement. \\
\fi

An appearance based metric is centred around using the perceivable difference between two corresponding raster images that are produced by the renderer. The difference can be calculated as the average sum of squared differences between all corresponding pixels, using the euclidean distance between two RGB vectors as representation of the distance between two pixel values. There are more complex methods of difference calculation between two vectors but this works well in this domain. If the difference between the vectors is small then the model is a good representation of appearance in this specific view, a total can be given as the integral over a finite set of viewpoints. The benefits of this method is that similarity of appearance is directly measured and occluded details can be removed without introduction of any error. The problems are that sufficient sampling of the possible viewpoints needs to be done so as to avoid removing perceptually important features, which leads to expensive rendering step sometimes being required, only a reduced number of samples can be taken.\\

A geometric based metric is based around producing a geometrically faithful representation of the data using techniques derived from function approximation. This does not allow for removal of features that are occluded as this is not known, which leads to an increased number of points being fitted to, however many viewpoints are not calculated as all features are represented. \\

The appearance based metric should be calculated after a model is displayed, this is towards the end of the pipeline. The geometric based metric should be done after the rendering but before the model is displayed.

\section*{Question Two}

\iffalse
10 marks \\
100 words \\
Explain how the Hausdorff distance can serve as a metric to determine the dissimilarity
between two polygon meshes, even when these meshes are formed by different number
vertices and connectivity. \\
\fi

The Hausdorff distance can be applied where there are a miss matched number of points in each of the meshes as they are not 'paired up' in such a way that this is necessary. A point from $M_1$ will calculate the distance to the nearest point in the mesh $M_2$, this is done in such a way that multiple points from $M_1$ can measure a distance to a single point in$M_2$. This is only done within a local area and if no point is found the distance is set at a maximum. This is also done backwards; $M_2$ points are matched to the nearest $M_1$ points, the two sets of distances are then used to give a metric for comparability, be that mean of all values or sum of all values.

\section*{Question Three}

\iffalse
20 marks \\
200 words \\
Describe the data structure of progressive meshes. Analyse the rendering efficiency of
progressive meshes visualisation, given that the user is allowed to freely rotate the viewpoint
during the visualisation process. \\
\fi

Providing the same functionality as the simplification stream, meaning that at any point we can reconstruct any intermediate model in the simplification process. The benefits of the progressive over the simplification is that the resulting representation can be smaller than the original model and reconstruction time is proportional to the desired approximation size. The progressive mesh exploits the fact that the contraction operation is reversible and is in essence a reversed simplification stream. For each of the contractions in the simplification stream we define a corresponding inverse, called a vertex split. Along with the base mesh or original model we can store each of these vertex splits, each must encode the vertex being split, positions of the two resulting vertices, and which triangles to introduce into the mesh. Not only being able to encode intermediate steps but also being an efficient compression technique. \\

Not sure about the rendering efficiency.

\section*{Question Four}

\iffalse
10 marks \\
100 marks \\
Explain how progressive meshes implement the refinement and decimation processes. \\
\fi

The refinement process data structures stores the data split that occurs for each of the vertices, this allows for each vertex to be split into two, of which the triangles stored as part of the data structure along with the coordinates of the two new vertices fit allowing for greater fitting to the model and higher granularity, this is the refinement process. The decimation process is calculated using the data split, as this is the inverse of the contraction operation, it is a straightforward inverse to calculate the corresponding contraction operation for each of the data splits, this allows for the decimation process to be done.

\section*{Question Five}

\iffalse
20 marks \\
200 words \\
Analyse how the incorporation of level-of-detail modeling impacts the rendering performance
and network bandwidth consumption of a large distributed virtual environment system.
Evaluate the suitability of using progressive meshes to implement the level-of-detail modeling
in such a system. \\
Note that in the above distributed virtual environment system, all graphics models of the virtual
environment are maintained by a remote server. During runtime, each client will download
relevant graphics models on-demand from the server to support interaction and visualisation. \\
\fi



\section*{Question Six}

\iffalse
20 marks \\
200 words \\
Explain the main issue of applying level-of-detail modeling to support interactive visualisation
of a large 3D scene, given that the user is allowed to change the viewpoint from time to time.
Describe two different methods to tackle such a challenge. \\
\fi



\end{document}